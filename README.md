# Kicktipp Predictor V4

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A machine learning-powered football match prediction system using a cascaded two-stage architecture. Predicts match outcomes (Home/Draw/Away) with calibrated probabilities using XGBoost classifiers.

## ğŸ¯ Overview

V4 introduces a **cascaded, two-stage classifier** that models match outcomes more directly and robustly than previous versions:

* **Stage 1 (Gatekeeper):** Binary classifier predicts `Draw` vs `NotDraw`
* **Stage 2 (Finisher):** Binary classifier predicts `HomeWin` vs `AwayWin` (conditioned on NotDraw)

Final probabilities are combined via the law of total probability to produce calibrated H/D/A predictions. This design targets realistic draw rates (18-28%) while improving accuracy and interpretability.

### Key Features

- âœ… **Cascaded Architecture:** Two-stage binary classification for robust predictions
- âœ… **Feature Engineering:** Elo ratings, team form, schedule context, and more
- âœ… **Dynamic Evaluation:** Expanding-window retraining simulating real-world usage
- âœ… **Hyperparameter Tuning:** Optuna-based optimization for both classifiers
- âœ… **Rich CLI:** Easy-to-use commands for training, prediction, and evaluation
- âœ… **Web Interface:** Flask-based UI for interactive predictions (optional)

---

## ğŸ“‹ Table of Contents

- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [CLI Commands](#-cli-commands)
- [Architecture](#-architecture)
- [Configuration](#-configuration)
- [Performance](#-performance)
- [Development](#-development)
- [Project Structure](#-project-structure)
- [License](#-license)

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- pip and virtualenv

### Basic Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/kicktipp-predictor.git
cd kicktipp-predictor

# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install base dependencies
pip install -e .
```

### Installation with Optional Extras

```bash
# For development (linting, type checking, pre-commit hooks)
pip install -e ".[dev]"

# For SHAP value analysis and plots
pip install -e ".[plots]"

# For hyperparameter tuning with Optuna
pip install -e ".[tuning]"

# Install everything
pip install -e ".[dev,plots,tuning]"
```

**Note for zsh users:** Quote the brackets to avoid globbing:
```bash
pip install -e '.[dev,plots,tuning]'
```

---

## âš¡ Quick Start

### 1. Train the Model

Train on the last 5 seasons of data:

```bash
python -m kicktipp_predictor.cli train --seasons-back 5
```

This will:
- Fetch historical match data
- Engineer features (Elo, form, schedule context)
- Train two XGBoost classifiers (draw gatekeeper + win finisher)
- Save models to `data/models/`

### 2. Make Predictions

Predict upcoming matches in the next 7 days:

```bash
python -m kicktipp_predictor.cli predict --days 7
```

Or predict a specific matchday:

```bash
python -m kicktipp_predictor.cli predict --matchday 15
```

### 3. Evaluate Performance

Run expanding-window evaluation on a season:

```bash
python -m kicktipp_predictor.cli evaluate --retrain-every 1
```

This simulates real-world usage by retraining before each matchday and evaluating predictions.

---

## ğŸ› ï¸ CLI Commands

### `train`

Train the cascaded predictor on historical data.

```bash
python -m kicktipp_predictor.cli train [OPTIONS]
```

**Options:**
- `--seasons-back INTEGER`: Number of past seasons to use for training (default: 5)
- `--validate / --no-validate`: Run 3-fold CV diagnostics after training (default: `--no-validate`)

**Example:**
```bash
python -m kicktipp_predictor.cli train --seasons-back 3
```

Optionally include CV diagnostics during development:
```bash
python -m kicktipp_predictor.cli train --seasons-back 3 --validate
```

---

### `predict`

Make predictions for upcoming matches.

```bash
python -m kicktipp_predictor.cli predict [OPTIONS]
```

**Options:**
- `--days INTEGER`: Days ahead to predict (default: 7)
- `--matchday INTEGER`: Specific matchday to predict (optional)

**Examples:**
```bash
# Predict next 14 days
python -m kicktipp_predictor.cli predict --days 14

# Predict matchday 20
python -m kicktipp_predictor.cli predict --matchday 20
```

---

### `evaluate`

Evaluate season performance with expanding-window retraining.

```bash
python -m kicktipp_predictor.cli evaluate [OPTIONS]
```

**Options:**
- `--season INTEGER`: Season to evaluate (default: current season)
- `--retrain-every INTEGER`: Retrain model every N matchdays (default: 1)
- `--start-matchday INTEGER`: Starting matchday for evaluation (default: 10)

**Example:**
```bash
python -m kicktipp_predictor.cli evaluate --season 2023 --retrain-every 2
```

This outputs:
- Overall metrics (accuracy, log loss, Brier score, RPS)
- Per-matchday performance
- Confusion matrix
- Predicted vs actual outcome distribution

---

### `tune`

Run Optuna-based hyperparameter tuning.

```bash
python -m kicktipp_predictor.cli tune [OPTIONS]
```

**Options:**
- `--n-trials INTEGER`: Number of Optuna trials (default: 100)
- `--seasons-back INTEGER`: Seasons for training data (default: 5)
- `--model-to-tune TEXT`: Which model to tune: "draw", "win", or "both" (default: "both")

**Example:**
```bash
python -m kicktipp_predictor.cli tune --n-trials 200 --seasons-back 4
```

**Note:** Requires the `tuning` extra to be installed.

---

### `web`

Launch the Flask web interface (if implemented).

```bash
python -m kicktipp_predictor.cli web
```

---

## ğŸ—ï¸ Architecture

### Cascaded Prediction Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Historical Match Data   â”‚
â”‚  (Bundesliga, etc.)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Engineering     â”‚
â”‚  â€¢ Elo Ratings           â”‚
â”‚  â€¢ Team Form (5-match)   â”‚
â”‚  â€¢ Schedule Context      â”‚
â”‚  â€¢ Head-to-Head Stats    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Draw Classifierâ”‚
â”‚  P(Draw) vs P(NotDraw)   â”‚
â”‚  (XGBoost Binary)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Win Classifier â”‚
â”‚  P(Home|ND) vs P(Away|ND)â”‚
â”‚  (XGBoost Binary)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Probability Combination â”‚
â”‚  P(H) = P(ND)*P(H|ND)    â”‚
â”‚  P(A) = P(ND)*P(A|ND)    â”‚
â”‚  P(D) = P(Draw)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final H/D/A Predictions â”‚
â”‚  (Normalized)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Cascaded?

1. **Realistic Draw Rates:** Previous models often under-predicted draws (V3: 0.8%). The gatekeeper explicitly models draws, achieving 18-28% predicted draw rates.
2. **Specialized Classifiers:** Each stage focuses on a specific binary decision, improving accuracy.
3. **Better Calibration:** Combining probabilities via law of total probability ensures valid probability distributions.
4. **Interpretability:** Easier to analyze where predictions fail (draw detection vs. home/away distinction).

---

## âš™ï¸ Configuration

Configuration is managed in `src/kicktipp_predictor/config.py` using Python dataclasses.

### Key Parameters

#### Draw Classifier (Stage 1)
```python
draw_n_estimators: int = 400
draw_max_depth: int = 5
draw_learning_rate: float = 0.05
draw_subsample: float = 0.7
draw_colsample_bytree: float = 0.7
draw_scale_pos_weight: float = 3.0  # Balances class imbalance
```

#### Win Classifier (Stage 2)
```python
win_n_estimators: int = 800
win_max_depth: int = 6
win_learning_rate: float = 0.1
win_subsample: float = 0.8
win_colsample_bytree: float = 0.8
```

### Modifying Configuration

Edit `src/kicktipp_predictor/config.py` or use environment variables/config files as needed.

---

## ğŸ“Š Performance

V4 targets the following performance metrics on Bundesliga data:

| Metric | Target | V3 Baseline |
|--------|--------|-------------|
| **Accuracy** | 40-50% | 31.7% |
| **Predicted Draw Rate** | 18-28% | 0.8% |
| **Log Loss** | < 1.0 | 1.15 |
| **Brier Score** | < 0.5 | 0.58 |
| **RPS** | < 0.25 | 0.28 |

**Note:** Performance varies by league, season, and training data size. Run `evaluate` to benchmark on your data.

### Confusion Matrix (Typical)

```
           Predicted
Actual    H    D    A
  H      [45]  12   8
  D       9  [18]  10
  A       7   11  [42]
```

The model excels at distinguishing home wins from away wins, with draws being the most challenging outcome (as expected in football).

---

## ğŸ‘¨â€ğŸ’» Development

### Setup Development Environment

```bash
pip install -e ".[dev]"
pre-commit install
```

### Code Quality Tools

- **Linting:** `ruff check src/ tests/`
- **Formatting:** `ruff format src/ tests/`
- **Type Checking:** `mypy src/`
- **Tests:** `pytest tests/`

### Pre-commit Hooks

The project uses pre-commit hooks to ensure code quality:
- Ruff formatting and linting
- Trailing whitespace removal
- YAML/JSON validation

### Running Tests

```bash
pytest tests/ -v
```

---

## ğŸ“ Project Structure

```
kicktipp-predictor/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ kicktipp_predictor/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cli.py              # CLI commands
â”‚       â”œâ”€â”€ predictor.py        # CascadedPredictor class
â”‚       â”œâ”€â”€ data.py             # Data loading & feature engineering
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â”œâ”€â”€ evaluate.py         # Evaluation logic
â”‚       â”œâ”€â”€ tune.py             # Optuna tuning
â”‚       â”œâ”€â”€ metrics.py          # Custom metrics
â”‚       â””â”€â”€ web/                # Flask web interface (optional)
â”œâ”€â”€ tests/                      # Unit and integration tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/                  # Cached match data
â”‚   â””â”€â”€ models/                 # Trained model artifacts
â”œâ”€â”€ docs/                       # Additional documentation
â”œâ”€â”€ scripts/                    # Utility scripts
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ BLUEPRINT.md                # Detailed technical architecture
â”œâ”€â”€ ROADMAP.md                  # Future development plans
â””â”€â”€ LICENSE
```

---

## ğŸ“š Additional Documentation

- **[BLUEPRINT.md](BLUEPRINT.md):** Detailed technical architecture and implementation guide
- **[ROADMAP.md](ROADMAP.md):** Planned features and improvements
- **[docs/](docs/):** Additional guides and examples

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Ensure all tests pass and code is formatted with Ruff.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Data sourced from public football statistics APIs
- Built with XGBoost, scikit-learn, and Typer
- Inspired by modern football analytics and probabilistic modeling

---

## ğŸ“ Support

For questions, issues, or feature requests, please:
- Open an issue on GitHub
- Check existing documentation in `docs/`
- Review `BLUEPRINT.md` for technical details

---

**Happy Predicting! âš½ğŸ“ˆ**
