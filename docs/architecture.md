# V3 Architecture: Goal Difference Regression

The V3 architecture is built on a single, powerful premise: **the most direct path to predicting the outcome is to predict the goal difference.**

## The Central Component: A Single Regression Model

The multi-model pipeline in `predictor.py` is replaced by a single class, the `GoalDifferencePredictor`.

*   **Model:** A single `xgboost.XGBRegressor`.
*   **Target Variable:** The model is trained directly on the `goal_difference` column (`home_score - away_score`), a continuous numerical target.
*   **Input Features:** It uses the same rich feature set generated by `data.py` (Elo, form metrics, etc.).

## The Probabilistic Bridge: From Regression to Classification

A raw goal difference prediction (e.g., `+0.67`) is not enough; we need H/D/A probabilities for robust evaluation and betting-style applications. The "Probabilistic Bridge" is a new, crucial component that translates the regressor's output into a full probability distribution.

1.  **Initial Implementation (Thresholding):** For a quick, working baseline, we will use simple thresholds:
    *   Predicted `goal_diff > 0.5` → Home Win
    *   Predicted `goal_diff < -0.5` → Away Win
    *   Otherwise → Draw
    *(Note: The `0.5` boundary is a sensible starting point but can be tuned).*

2.  **Definitive Implementation (Probabilistic Translation):** The core innovation is to treat the regressor's output not as a point estimate, but as the *mean* (`μ`) of a probability distribution. This acknowledges the uncertainty in the prediction. We then calculate the probabilities by integrating over the relevant parts of the distribution.

    *   **Distribution Choice:** We can use a Normal distribution (`scipy.stats.norm`) or, more appropriately, a Skellam distribution (`scipy.stats.skellam`), which models the difference between two Poisson variables.
    *   **Calculation:**
        *   `P(Home Win) = 1 - CDF(0.5)`
        *   `P(Away Win) = CDF(-0.5)`
        *   `P(Draw) = CDF(0.5) - CDF(-0.5)`
    *   **New Hyperparameter:** The standard deviation (`σ`) of this distribution becomes a key, tunable hyperparameter that controls the model's confidence.

## Retained Assets: What Stays the Same

This is a strategic rebuild, not a complete rewrite. We will retain the high-quality engineering components:
*   **`data.py`:** The data loading, caching, and sophisticated feature engineering logic (especially the Elo system) are preserved.
*   **`evaluate.py`:** The dynamic, expanding-window evaluation framework remains perfectly suited to the task, as it consumes the H/D/A probabilities produced by our new "Probabilistic Bridge."
*   **`cli.py`:** The user-facing command-line interface will be re-wired to the new predictor but will maintain its familiar `train`, `predict`, and `evaluate` commands.
